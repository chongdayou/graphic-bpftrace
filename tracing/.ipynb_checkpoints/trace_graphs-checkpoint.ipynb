{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "09ec6832-2b34-429a-a40f-de85af5a298f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce28042d-c2fc-4eb3-87c2-f69ad0cc94ea",
   "metadata": {},
   "source": [
    "### process file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "5fcaccaa-1fe0-4298-8a04-44f91a0a2626",
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_key(key: str) -> int:\n",
    "    if not key:\n",
    "        return -1\n",
    "    \n",
    "    word_mapping = {\n",
    "        'true': 1,\n",
    "        'false': 0,\n",
    "        'exec()': 0,\n",
    "        'fork()': 1,\n",
    "        'exit()': 2,\n",
    "        'malloc()': 3,\n",
    "        'free()': 4,\n",
    "        'realloc()': 5\n",
    "    }\n",
    "    if key in word_mapping:\n",
    "        return word_mapping[key]\n",
    "    # bug: lifetime is a float, not handled correctly yet\n",
    "    try:\n",
    "        return int(key)\n",
    "    except ValueError:\n",
    "        return -1\n",
    "\n",
    "def add_stats_line(arr: np.ndarray | None, line: list[str]) -> np.ndarray:\n",
    "    if not line:\n",
    "        return arr if arr is not None else np.empty((0, 0), dtype=int)\n",
    "\n",
    "    vals = [parse_key(word) for word in line]\n",
    "    row = np.array(values, dtype=np.int64)[None, :] # trick to add a dimension to row\n",
    "\n",
    "    if arr is None or arr.size == 0:\n",
    "        #print('arr is None')\n",
    "        return row\n",
    "    if arr.dtype != np.int64:\n",
    "        arr = arr.astype(np.int64, copy=False)\n",
    "    if arr.ndim == 1: # if dimension of arr is 1\n",
    "        #print('arr is dimension 1')\n",
    "        arr = arr[None, :]\n",
    "    if arr.shape[1] != row.shape[1]:\n",
    "        raise ValueError(f'Column mismatch: arr has {arr.shape[1]} cols, row has {row.shape[1]} cols.')\n",
    "    return np.vstack((arr,row))\n",
    "\n",
    "stats = None\n",
    "with open(\"trace_results.csv\", 'r') as trace_csv:\n",
    "\ttrace_reader = csv.reader(trace_csv)\n",
    "\tnext(trace_reader)\n",
    "\n",
    "\tfor line in trace_reader:\n",
    "\t\tstats = add_stats_line(stats, line)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "22648644-8515-409f-bc53-c677df997a32",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'numpy.ndarray'>\n",
      "(130269, 8)\n",
      "2\n",
      "[[2570223624792         10655             1             4          9380\n",
      "            152             4            -1]\n",
      " [2570223630824         10651             1             4          9340\n",
      "            152            40            -1]\n",
      " [2570223636992         10644             1             4          9260\n",
      "             72            80            -1]\n",
      " [2570223643189         10644             1             4          9252\n",
      "             64             8            -1]\n",
      " [2570223927952         10644             1             2    2120208366\n",
      "             -1            -1            -1]]\n"
     ]
    }
   ],
   "source": [
    "print(type(stats))\n",
    "print(stats.shape)\n",
    "print(stats.ndim)\n",
    "print(stats[-5:])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "618e8c98-c242-42c9-a817-6f37d8d5b556",
   "metadata": {},
   "source": [
    "### ploting dynamic memory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "92f882fe-a010-4a42-8eef-2df9e438e9d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# list format: timestamp, tid, isMain, operation, stat1, stat2, stat3, stat4\n",
    "# operations: exec() marks the start of main thread, fork() marks start of child thread,\n",
    "# \t\tmalloc(), realloc(), free()\n",
    "# ismain: 0 == False, 1 == True\n",
    "# represent operations by int:\n",
    "# \t\texec() = 0, fork() = 1, exit() = 2, malloc() = 3, free() = 4, realloc() = 5\n",
    "# stats by operation:\n",
    "# \t\tmalloc(): stat1 = process heap size, stat2 = thread heap size, stat3 = size of malloc()\n",
    "# \t\trealloc(): stat1 = process heap size, stat2 = thread heap size, stat3 = old size, stat4 = new size\n",
    "# \t\tfree(): stat1 = process heap size, stat2 = thread heap size, stat3 = size freed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "b08a8fc3-cc79-4676-8967-e571984b9e0a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All threads recorded are: {0, 10651, 10652, 10653, 10654, 10655}.\n",
      "Relevant threads are: [0, 10651, 10652, 10653, 10654, 10655].\n",
      "130257 130257\n"
     ]
    }
   ],
   "source": [
    "threads_map = {}\n",
    "program_mem = []\n",
    "start_ms = stats[0][0] // 1000000\n",
    "threads = set()\n",
    "\n",
    "for row in stats:\n",
    "    tid = 0 if row[2] == 1 else row[1]\n",
    "    # add threads\n",
    "    if tid not in threads:\n",
    "        threads.add(int(tid))\n",
    "    if (row[3] == 0 or row[3] == 1) and tid not in threads_map:\n",
    "        threads_map[tid] = ([0],[0]) #time_ns, memory_bytes\n",
    "    if tid in threads_map and row[3] in [3,4,5]: # malloc(), free(), realloc()\n",
    "        timestamp = row[0] //1000000 - start_ms\n",
    "        threads_map[tid][0].append(timestamp)\n",
    "        threads_map[tid][1].append(row[5])\n",
    "        program_mem.append((timestamp,row[4]))\n",
    "\n",
    "print(f'All threads recorded are: {threads}.')\n",
    "print(f'Relevant threads are: {[int(tid) for tid in threads_map.keys()]}.')\n",
    "\n",
    "lines = {}\n",
    "plt.figure(figsize=(10,5))\n",
    "plt.xlabel('time since program starts (ms)')\n",
    "plt.ylabel('memory allocated (bytes)')\n",
    "plt.title('dynamic memory by time')\n",
    "\n",
    "# all threads dynamic memory plot\n",
    "for tid, (time, mem) in threads_map.items():\n",
    "    smooth_window = 3\n",
    "    # np.convolve with mode=valid only returns indices that can be convolved, so the first n-1 items in list is dropped\n",
    "    # therefore add a total of n-1=9 paddings to mem to balance out the cut\n",
    "    pad_left, pad_right = smooth_window // 2 - 1 if smooth_window % 2 == 0 else smooth_window // 2, smooth_window // 2\n",
    "    mem_padded = np.pad(mem, (pad_left, pad_right), mode='edge')\n",
    "    # each number is now the average of nth to n-9th number in mem\n",
    "    mem_smooth = np.convolve(mem_padded, np.ones(smooth_window)/smooth_window, mode='valid')\n",
    "    line, = plt.plot(time, mem_smooth, label=tid) # interesting unpack returned list of lines into a single line with ,\n",
    "    lines[tid] = line\n",
    "plt.legend([lines[0]], [\"main\"])\n",
    "plt.savefig(\"plots/dynamic_memory.png\")\n",
    "plt.cla()\n",
    "\n",
    "# selective threads dynamic memory plot\n",
    "plt.plot(threads_map[0][0], threads_map[0][1])\n",
    "child_line_count = 1\n",
    "child_thread = list(threads_map.keys())[child_line_count]\n",
    "plt.plot(threads_map[child_thread][0], threads_map[child_thread][1])\n",
    "plt.legend([\"main\", child_thread])\n",
    "plt.savefig(\"plots/two_threads_memory.png\")\n",
    "plt.cla()\n",
    "\n",
    "# process dynamic memory\n",
    "plt.title('process heap memory by time')\n",
    "time, mem = zip(*program_mem) #*iterable to unwrap\n",
    "print(len(time), len(mem))\n",
    "plt.plot(time, mem, label='process')\n",
    "plt.savefig('plots/process_memory.png')\n",
    "plt.clf()\n",
    "\n",
    "plt.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "abff79d8-995d-41ce-834f-71ea3fed73f1",
   "metadata": {},
   "source": [
    "## no owner version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "e50aef46-9304-42b4-8079-6f22c43c8cce",
   "metadata": {},
   "outputs": [
    {
     "ename": "OverflowError",
     "evalue": "Python int too large to convert to C long",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mOverflowError\u001b[39m                             Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[29]\u001b[39m\u001b[32m, line 48\u001b[39m\n\u001b[32m     45\u001b[39m \u001b[38;5;28mnext\u001b[39m(trace_reader)\n\u001b[32m     47\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m line \u001b[38;5;129;01min\u001b[39;00m trace_reader:\n\u001b[32m---> \u001b[39m\u001b[32m48\u001b[39m \tstats = \u001b[43madd_stats_line\u001b[49m\u001b[43m(\u001b[49m\u001b[43mstats\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mline\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[29]\u001b[39m\u001b[32m, line 28\u001b[39m, in \u001b[36madd_stats_line\u001b[39m\u001b[34m(arr, line)\u001b[39m\n\u001b[32m     25\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m arr \u001b[38;5;28;01mif\u001b[39;00m arr \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m np.empty((\u001b[32m0\u001b[39m, \u001b[32m0\u001b[39m), dtype=\u001b[38;5;28mint\u001b[39m)\n\u001b[32m     27\u001b[39m vals = [parse_key(word) \u001b[38;5;28;01mfor\u001b[39;00m word \u001b[38;5;129;01min\u001b[39;00m line]\n\u001b[32m---> \u001b[39m\u001b[32m28\u001b[39m row = \u001b[43mnp\u001b[49m\u001b[43m.\u001b[49m\u001b[43marray\u001b[49m\u001b[43m(\u001b[49m\u001b[43mvals\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[43m=\u001b[49m\u001b[43mnp\u001b[49m\u001b[43m.\u001b[49m\u001b[43mint64\u001b[49m\u001b[43m)\u001b[49m[\u001b[38;5;28;01mNone\u001b[39;00m, :] \u001b[38;5;66;03m# trick to add a dimension to row\u001b[39;00m\n\u001b[32m     30\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m arr \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mor\u001b[39;00m arr.size == \u001b[32m0\u001b[39m:\n\u001b[32m     31\u001b[39m     \u001b[38;5;66;03m#print('arr is None')\u001b[39;00m\n\u001b[32m     32\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m row\n",
      "\u001b[31mOverflowError\u001b[39m: Python int too large to convert to C long"
     ]
    }
   ],
   "source": [
    "def parse_key(key: str) -> int:\n",
    "    if not key:\n",
    "        return -1\n",
    "    \n",
    "    word_mapping = {\n",
    "        'true': 1,\n",
    "        'false': 0,\n",
    "        'exec()': 0,\n",
    "        'fork()': 1,\n",
    "        'exit()': 2,\n",
    "        'malloc()': 3,\n",
    "        'free()': 4,\n",
    "        'realloc()': 5\n",
    "    }\n",
    "    if key in word_mapping:\n",
    "        return word_mapping[key]\n",
    "    # bug: lifetime is a float, not handled correctly yet\n",
    "    try:\n",
    "        return int(key)\n",
    "    except ValueError:\n",
    "        return -1\n",
    "\n",
    "def add_stats_line(arr: np.ndarray | None, line: list[str]) -> np.ndarray:\n",
    "    if not line:\n",
    "        return arr if arr is not None else np.empty((0, 0), dtype=int)\n",
    "\n",
    "    vals = [parse_key(word) for word in line]\n",
    "    row = np.array(vals, dtype=np.int64)[None, :] # trick to add a dimension to row\n",
    "\n",
    "    if arr is None or arr.size == 0:\n",
    "        #print('arr is None')\n",
    "        return row\n",
    "    if arr.dtype != np.int64:\n",
    "        arr = arr.astype(np.int64, copy=False)\n",
    "    if arr.ndim == 1: # if dimension of arr is 1\n",
    "        #print('arr is dimension 1')\n",
    "        arr = arr[None, :]\n",
    "    if arr.shape[1] != row.shape[1]:\n",
    "        raise ValueError(f'Column mismatch: arr has {arr.shape[1]} cols, row has {row.shape[1]} cols.')\n",
    "    return np.vstack((arr,row))\n",
    "\n",
    "stats = None\n",
    "with open(\"trace_no_owner_results.csv\", 'r') as trace_csv:\n",
    "\ttrace_reader = csv.reader(trace_csv)\n",
    "\tnext(trace_reader)\n",
    "\n",
    "\tfor line in trace_reader:\n",
    "\t\tstats = add_stats_line(stats, line)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "197952c8-90f4-477a-823e-7efbb7aae1cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(type(stats))\n",
    "print(stats.shape)\n",
    "print(stats.ndim)\n",
    "print(stats[-5:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5eee373b-5939-4f6e-b305-a320c7a4ecb1",
   "metadata": {},
   "outputs": [],
   "source": [
    "threads_map = {}\n",
    "program_mem = []\n",
    "start_ms = stats[0][0] // 1000000\n",
    "threads = set()\n",
    "\n",
    "for row in stats:\n",
    "    tid = 0 if row[2] == 1 else row[1]\n",
    "    # add threads\n",
    "    if tid not in threads:\n",
    "        threads.add(int(tid))\n",
    "    if (row[3] == 0 or row[3] == 1) and tid not in threads_map:\n",
    "        threads_map[tid] = ([0],[0]) #time_ns, memory_bytes\n",
    "    if tid in threads_map and row[3] in [3,4,5]: # malloc(), free(), realloc()\n",
    "        timestamp = row[0] //1000000 - start_ms\n",
    "        threads_map[tid][0].append(timestamp)\n",
    "        threads_map[tid][1].append(row[5])\n",
    "        program_mem.append((timestamp,row[4]))\n",
    "\n",
    "print(f'All threads recorded are: {threads}.')\n",
    "print(f'Relevant threads are: {[int(tid) for tid in threads_map.keys()]}.')\n",
    "\n",
    "lines = {}\n",
    "plt.figure(figsize=(10,5))\n",
    "plt.xlabel('time since program starts (ms)')\n",
    "plt.ylabel('memory allocated (bytes)')\n",
    "plt.title('dynamic memory by time')\n",
    "\n",
    "# all threads dynamic memory plot\n",
    "for tid, (time, mem) in threads_map.items():\n",
    "    smooth_window = 3\n",
    "    # np.convolve with mode=valid only returns indices that can be convolved, so the first n-1 items in list is dropped\n",
    "    # therefore add a total of n-1=9 paddings to mem to balance out the cut\n",
    "    pad_left, pad_right = smooth_window // 2 - 1 if smooth_window % 2 == 0 else smooth_window // 2, smooth_window // 2\n",
    "    mem_padded = np.pad(mem, (pad_left, pad_right), mode='edge')\n",
    "    # each number is now the average of nth to n-9th number in mem\n",
    "    mem_smooth = np.convolve(mem_padded, np.ones(smooth_window)/smooth_window, mode='valid')\n",
    "    line, = plt.plot(time, mem_smooth, label=tid) # interesting unpack returned list of lines into a single line with ,\n",
    "    lines[tid] = line\n",
    "plt.legend([lines[0]], [\"main\"])\n",
    "plt.savefig(\"plots/no_owner_dynamic_memory.png\")\n",
    "plt.cla()\n",
    "\n",
    "# selective threads dynamic memory plot\n",
    "plt.plot(threads_map[0][0], threads_map[0][1])\n",
    "child_line_count = 1\n",
    "child_thread = list(threads_map.keys())[child_line_count]\n",
    "plt.plot(threads_map[child_thread][0], threads_map[child_thread][1])\n",
    "plt.legend([\"main\", child_thread])\n",
    "plt.savefig(\"plots/no_owner_two_threads_memory.png\")\n",
    "plt.cla()\n",
    "\n",
    "# process dynamic memory\n",
    "plt.title('process heap memory by time')\n",
    "plt.xlabel('time since program starts (ms)')\n",
    "plt.ylabel('memory allocated (bytes)')\n",
    "time, mem = zip(*program_mem) #*iterable to unwrap\n",
    "print(len(time), len(mem))\n",
    "plt.plot(time, mem, label='process')\n",
    "plt.savefig('plots/no_owner_process_memory.png')\n",
    "plt.clf()\n",
    "\n",
    "plt.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
